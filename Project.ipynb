{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "757bdb90-a073-485f-bef2-37200cc91f0c",
      "metadata": {
        "id": "757bdb90-a073-485f-bef2-37200cc91f0c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from scipy.io import arff\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import joblib\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f23ba4c6-f411-4406-9254-2390362c0c6c",
      "metadata": {
        "id": "f23ba4c6-f411-4406-9254-2390362c0c6c"
      },
      "outputs": [],
      "source": [
        "# Load the ARFF file using scipy\n",
        "data, meta = arff.loadarff('bone-marrow.arff')\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Decode byte strings to normal strings (if necessary)\n",
        "df = df.map(lambda x: x.decode() if isinstance(x, bytes) else x)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0542f7a-86f9-41a1-b91d-57948ff38026",
      "metadata": {
        "id": "e0542f7a-86f9-41a1-b91d-57948ff38026"
      },
      "outputs": [],
      "source": [
        "# Define the name for the output Excel file\n",
        "excel_file_name = 'my_dataset.xlsx'\n",
        "\n",
        "# Step 4: Export your existing DataFrame to an Excel file\n",
        "# The to_excel() function writes the contents of 'df' to an .xlsx file.\n",
        "# We use 'index=False' to prevent pandas from writing the row numbers\n",
        "# into the first column of the Excel sheet.\n",
        "df.to_excel(excel_file_name, index=False, sheet_name='Data')\n",
        "\n",
        "print(f\"Success! Your DataFrame has been saved to the file: '{excel_file_name}'\")\n",
        "print(\"You can now download it from the Jupyter file browser.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "684eaf16-d755-41b2-860c-45ad8f785fc2",
      "metadata": {
        "scrolled": true,
        "id": "684eaf16-d755-41b2-860c-45ad8f785fc2"
      },
      "outputs": [],
      "source": [
        "# Replace '?' with NaN\n",
        "df.replace('?', pd.NA, inplace=True)\n",
        "\n",
        "# Identify numerical and categorical features\n",
        "numerical_features = ['Donorage', 'CD34kgx10d6', 'CD3dCD34', 'CD3dkgx10d8', 'Rbodymass', 'ANCrecovery', 'PLTrecovery', 'time_to_aGvHD_III_IV', 'survival_time']\n",
        "categorical_features = ['ReAcipientgender', 'Stemcellsource', 'Donorage35', 'IIIV', 'Gendermatch', 'DonorABO', 'RecipientABO', 'RecipientRh', 'ABOmatch', 'CMVstatus', 'DonorCMV', 'RecipientCMV', 'Disease', 'Riskgroup', 'Txpostrelapse', 'Diseasegroup', 'HLAmatch', 'HLAmismatch', 'Antigen', 'Alel', 'HLAgrI', 'Recipientage', 'Recipientage10', 'Recipientageint', 'Relapse', 'aGvHDIIIIV', 'extcGvHD']\n",
        "\n",
        "# Convert numerical columns to numeric types\n",
        "df[numerical_features] = df[numerical_features].apply(pd.to_numeric)\n",
        "\n",
        "# Print to verify columns\n",
        "print(f\"Numerical Features: {numerical_features}\")\n",
        "print(f\"Categorical Features: {categorical_features}\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06a1e8c1-8481-43eb-a222-6704ffec619f",
      "metadata": {
        "id": "06a1e8c1-8481-43eb-a222-6704ffec619f"
      },
      "outputs": [],
      "source": [
        "# Set the option to avoid the FutureWarning\n",
        "pd.set_option('future.no_silent_downcasting', True)\n",
        "\n",
        "# Replace '?' with NaN and then with np.nan\n",
        "df.replace('?', np.nan, inplace=True)\n",
        "df = df.replace({pd.NA: np.nan})\n",
        "\n",
        "# Identify numerical and categorical features\n",
        "numerical_features = ['Donorage', 'CD34kgx10d6', 'CD3dCD34', 'CD3dkgx10d8', 'Rbodymass', 'ANCrecovery', 'PLTrecovery', 'time_to_aGvHD_III_IV', 'survival_time']\n",
        "categorical_features = ['Recipientgender', 'Stemcellsource', 'Donorage35', 'IIIV', 'Gendermatch', 'DonorABO', 'RecipientABO', 'RecipientRh', 'ABOmatch', 'CMVstatus', 'DonorCMV', 'RecipientCMV', 'Disease', 'Riskgroup', 'Txpostrelapse', 'Diseasegroup', 'HLAmatch', 'HLAmismatch', 'Antigen', 'Alel', 'HLAgrI', 'Recipientage', 'Recipientage10', 'Recipientageint', 'Relapse', 'aGvHDIIIIV', 'extcGvHD']\n",
        "\n",
        "# Convert numerical columns to numeric types\n",
        "df[numerical_features] = df[numerical_features].apply(pd.to_numeric)\n",
        "\n",
        "# Define imputers\n",
        "num_imputer = SimpleImputer(strategy='mean')\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Impute missing values for numerical features\n",
        "df[numerical_features] = num_imputer.fit_transform(df[numerical_features])\n",
        "\n",
        "# Impute missing values for categorical features\n",
        "df[categorical_features] = cat_imputer.fit_transform(df[categorical_features])\n",
        "\n",
        "# Print to verify imputed data\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8236257-f911-4476-8dff-94f9155574d2",
      "metadata": {
        "id": "d8236257-f911-4476-8dff-94f9155574d2"
      },
      "outputs": [],
      "source": [
        "# Encode categorical features\n",
        "df = pd.get_dummies(df, columns=categorical_features, drop_first=True)\n",
        "\n",
        "# Print to verify encoded data\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96223ad9-7761-4ad8-80c8-52537034f4c7",
      "metadata": {
        "id": "96223ad9-7761-4ad8-80c8-52537034f4c7"
      },
      "outputs": [],
      "source": [
        "# Calculate correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Select upper triangle of correlation matrix\n",
        "upper = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
        "\n",
        "# Find index of feature columns with correlation greater than 0.7\n",
        "to_drop = [column for column in upper.columns if any(upper[column] > 0.7)]\n",
        "\n",
        "# Drop features\n",
        "df.drop(columns=to_drop, inplace=True)\n",
        "\n",
        "# Print to verify dropped features\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d79ff7c1-1648-452c-bee1-71626355ba6d",
      "metadata": {
        "id": "d79ff7c1-1648-452c-bee1-71626355ba6d"
      },
      "outputs": [],
      "source": [
        "# Data scaling\n",
        "scaler = StandardScaler()\n",
        "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
        "\n",
        "# Display the DataFrame after scaling\n",
        "print(\"DataFrame after pre-processing:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b04d64c-bd72-4143-9ff8-c1543a72f73b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b04d64c-bd72-4143-9ff8-c1543a72f73b",
        "outputId": "1e5706eb-58da-4074-fc19-43e5bacd1317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.9210526315789473\n",
            "Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      1.00      0.94        22\n",
            "         1.0       1.00      0.81      0.90        16\n",
            "\n",
            "    accuracy                           0.92        38\n",
            "   macro avg       0.94      0.91      0.92        38\n",
            "weighted avg       0.93      0.92      0.92        38\n",
            "\n",
            "Random Forest Feature Importances:\n",
            "               Feature  Importance\n",
            "8        survival_time    0.313613\n",
            "6          PLTrecovery    0.065606\n",
            "168          Relapse_1    0.049675\n",
            "3          CD3dkgx10d8    0.048686\n",
            "1          CD34kgx10d6    0.046670\n",
            "..                 ...         ...\n",
            "127  Recipientage_13.0    0.000000\n",
            "153  Recipientage_17.4    0.000000\n",
            "151  Recipientage_17.0    0.000000\n",
            "154  Recipientage_17.5    0.000000\n",
            "163  Recipientage_18.8    0.000000\n",
            "\n",
            "[170 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# Sample target variable\n",
        "target = 'survival_status'\n",
        "\n",
        "# Ensure the target variable is correctly identified\n",
        "if target not in df.columns:\n",
        "    raise ValueError(\"The target column 'survival_status' is not found in the dataset. Please ensure the target column exists.\")\n",
        "\n",
        "# Split the data into features and target\n",
        "X = df.drop(columns=[target])\n",
        "y = df[target]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest model and evaluate\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Random Forest Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "# Feature importance using Random Forest\n",
        "rf_importances = rf.feature_importances_\n",
        "rf_features = pd.DataFrame({'Feature': X.columns, 'Importance': rf_importances})\n",
        "rf_features = rf_features.sort_values(by='Importance', ascending=False)\n",
        "print(\"Random Forest Feature Importances:\")\n",
        "print(rf_features)\n",
        "\n",
        "# Recursive Feature Elimination with Cross-Validation for Random Forest\n",
        "rfecv = RFECV(estimator=rf, step=1, cv=5, scoring='accuracy')\n",
        "rfecv.fit(X_train, y_train)\n",
        "print(\"Optimal number of features for Random Forest:\", rfecv.n_features_)\n",
        "print(\"Best features selected by Recursive Feature Elimination:\")\n",
        "print(X.columns[rfecv.support_])\n",
        "\n",
        "# Train and evaluate additional models similarly and get feature importances\n",
        "# XGBoost\n",
        "xgb = XGBClassifier(random_state=42)\n",
        "xgb.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
        "print(\"XGBoost Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_xgb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3163cc6-0cbd-4bb6-8833-b0ea4d24b2f0",
      "metadata": {
        "id": "d3163cc6-0cbd-4bb6-8833-b0ea4d24b2f0"
      },
      "outputs": [],
      "source": [
        "# Hyper-Parameter Tuning for KNN\n",
        "param_grid_knn = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
        "}\n",
        "\n",
        "grid_search_knn = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=param_grid_knn, cv=5, scoring='accuracy', n_jobs=1)\n",
        "grid_search_knn.fit(X_train, y_train)\n",
        "print(\"Best parameters for KNN:\", grid_search_knn.best_params_)\n",
        "best_knn = grid_search_knn.best_estimator_\n",
        "y_pred_best_knn = best_knn.predict(X_test)\n",
        "print(\"Tuned KNN Accuracy:\", accuracy_score(y_test, y_pred_best_knn))\n",
        "print(\"Tuned KNN Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_best_knn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d85d480-f595-43ef-b57e-79ae95012610",
      "metadata": {
        "id": "8d85d480-f595-43ef-b57e-79ae95012610"
      },
      "outputs": [],
      "source": [
        "# Additional metrics for the tuned model\n",
        "roc_auc_best_knn = roc_auc_score(y_test, best_knn.predict_proba(X_test)[:, 1])\n",
        "print(\"Tuned KNN AUC-ROC:\", roc_auc_best_knn)\n",
        "conf_matrix_best_knn = confusion_matrix(y_test, y_pred_best_knn)\n",
        "print(\"Tuned KNN Confusion Matrix:\")\n",
        "print(conf_matrix_best_knn)\n",
        "\n",
        "# Save the trained Random Forest model\n",
        "joblib.dump(rf, 'rf_model.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2575d459-2088-4c98-8cbd-b9a3a5c1f739",
      "metadata": {
        "id": "2575d459-2088-4c98-8cbd-b9a3a5c1f739"
      },
      "outputs": [],
      "source": [
        "#Define the preprocess function\n",
        "def preprocess(input_df):\n",
        "    # Identify numerical and categorical features\n",
        "    numerical_features = ['Donorage', 'CD34kgx10d6', 'CD3dCD34', 'CD3dkgx10d8', 'Rbodymass', 'ANCrecovery', 'PLTrecovery', 'time_to_aGvHD_III_IV', 'survival_time']\n",
        "    categorical_features = ['Recipientgender', 'Stemcellsource', 'Donorage35', 'IIIV', 'Gendermatch', 'DonorABO', 'RecipientABO', 'RecipientRh', 'ABOmatch', 'CMVstatus', 'DonorCMV', 'RecipientCMV', 'Disease', 'Riskgroup', 'Txpostrelapse', 'Diseasegroup', 'HLAmatch', 'HLAmismatch', 'Antigen', 'Alel', 'HLAgrI', 'Recipientage', 'Recipientage10', 'Recipientageint', 'Relapse', 'aGvHDIIIIV', 'extcGvHD']\n",
        "\n",
        "    # Convert numerical columns to numeric types\n",
        "    input_df[numerical_features] = input_df[numerical_features].apply(pd.to_numeric)\n",
        "\n",
        "    # Define imputers\n",
        "    num_imputer = SimpleImputer(strategy='mean')\n",
        "    cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "    # Impute missing values for numerical features\n",
        "    input_df[numerical_features] = num_imputer.fit_transform(input_df[numerical_features])\n",
        "\n",
        "    # Impute missing values for categorical features\n",
        "    input_df[categorical_features] = cat_imputer.fit_transform(input_df[categorical_features])\n",
        "\n",
        "    # Encode categorical features\n",
        "    input_df = pd.get_dummies(input_df, columns=categorical_features, drop_first=True)\n",
        "\n",
        "    # Data scaling\n",
        "    scaler = StandardScaler()\n",
        "    input_df[numerical_features] = scaler.transform(input_df[numerical_features])\n",
        "\n",
        "    return input_df\n",
        "\n",
        "# Load the trained Random Forest model\n",
        "rf_model = joblib.load('rf_model.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f789a7fe-70a4-4a6b-b338-b270410de22e",
      "metadata": {
        "id": "f789a7fe-70a4-4a6b-b338-b270410de22e"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "616efea0-b8b8-402c-8b46-48c4f5f13e1a",
      "metadata": {
        "id": "616efea0-b8b8-402c-8b46-48c4f5f13e1a"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import joblib\n",
        "print(sklearn.__version__)\n",
        "print(joblib.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7913a6a5-91b2-4b78-b38a-7f00eb5b68f7",
      "metadata": {
        "id": "7913a6a5-91b2-4b78-b38a-7f00eb5b68f7"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "try:\n",
        "    model_pipeline = joblib.load('rf_model_pipeline.joblib')\n",
        "    print(\"Pipeline loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the pipeline: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08eec99a-e399-419d-89f8-20d83ec94634",
      "metadata": {
        "id": "08eec99a-e399-419d-89f8-20d83ec94634"
      },
      "outputs": [],
      "source": [
        "import arff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a8bea6a-f33c-4363-92c6-bebd5c17af76",
      "metadata": {
        "id": "5a8bea6a-f33c-4363-92c6-bebd5c17af76"
      },
      "outputs": [],
      "source": [
        "import scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7ede419-f006-4786-88d4-f4a6222e158c",
      "metadata": {
        "id": "c7ede419-f006-4786-88d4-f4a6222e158c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import scipy.io.arff\n",
        "import joblib\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import arff\n",
        "\n",
        "# Load the ARFF file directly with the file path as a string\n",
        "data, meta = scipy.io.arff.loadarff('bone-marrow.arff')\n",
        "\n",
        "# Convert ARFF data to a list\n",
        "data_list = [list(record) for record in data]\n",
        "\n",
        "attribute_names = meta.names()\n",
        "\n",
        "# Create DataFrame from the ARFF file\n",
        "df = pd.DataFrame(data, columns = attribute_names)\n",
        "\n",
        "# Replace '?' with NaN\n",
        "df.replace('?', pd.NA, inplace=True)\n",
        "\n",
        "# Identify numerical and categorical features\n",
        "numerical_features = ['Donorage', 'CD34kgx10d6', 'CD3dCD34', 'CD3dkgx10d8', 'Rbodymass', 'ANCrecovery', 'PLTrecovery', 'time_to_aGvHD_III_IV', 'survival_time']\n",
        "categorical_features = ['Recipientgender', 'Stemcellsource', 'Donorage35', 'IIIV', 'Gendermatch', 'DonorABO', 'RecipientABO', 'RecipientRh', 'ABOmatch', 'CMVstatus', 'DonorCMV', 'RecipientCMV', 'Disease', 'Riskgroup', 'Txpostrelapse', 'Diseasegroup', 'HLAmatch', 'HLAmismatch', 'Antigen', 'Alel', 'HLAgrI', 'Recipientage', 'Recipientage10', 'Recipientageint', 'Relapse', 'aGvHDIIIIV', 'extcGvHD']\n",
        "\n",
        "# Convert numerical columns to numeric types\n",
        "df[numerical_features] = df[numerical_features].apply(pd.to_numeric)\n",
        "\n",
        "# Define imputers\n",
        "num_imputer = SimpleImputer(strategy='mean')\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Define the preprocessing pipeline\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', num_imputer),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', cat_imputer),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Create a pipeline with the preprocessor and the model\n",
        "model_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Sample target variable\n",
        "target = 'survival_status'\n",
        "\n",
        "# Split the data into features and target\n",
        "X = df.drop(columns=[target])\n",
        "y = df[target]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the model pipeline\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Save the model pipeline\n",
        "joblib.dump(model_pipeline, 'rf_model_pipeline.joblib')\n",
        "\n",
        "# Verify the file is saved\n",
        "import os\n",
        "  # Ensure the file is saved in the directory\n",
        "\n",
        "# Load the model pipeline\n",
        "model_pipeline = joblib.load('rf_model_pipeline.joblib')\n",
        "\n",
        "# Define the prediction function\n",
        "def predict_survival(input_data):\n",
        "    input_df = pd.DataFrame([input_data])\n",
        "    prediction = model_pipeline.predict(input_df)\n",
        "    survival_status = 'Survived' if prediction[0] == 1 else 'Did not survive'\n",
        "    return survival_status\n",
        "\n",
        "# Example usage of the predict_survival function\n",
        "input_data = {\n",
        "    'Donorage': 35,\n",
        "    'Recipientgender': 1,\n",
        "    'Stemcellsource': 1,\n",
        "    'Donorage35': 0,\n",
        "    'IIIV': 1,\n",
        "    'Gendermatch': 1,\n",
        "    'DonorABO': 1,\n",
        "    'RecipientABO': 1,\n",
        "    'RecipientRh': 1,\n",
        "    'ABOmatch': 1,\n",
        "    'CMVstatus': 1,\n",
        "    'DonorCMV': 1,\n",
        "    'RecipientCMV': 1,\n",
        "    'Disease': 1,\n",
        "    'Riskgroup': 1,\n",
        "    'Txpostrelapse': 0,\n",
        "    'Diseasegroup': 1,\n",
        "    'HLAmatch': 1,\n",
        "    'HLAmismatch': 0,\n",
        "    'Antigen': 1,\n",
        "    'Alel': 1,\n",
        "    'HLAgrI': 1,\n",
        "    'Recipientage': 30,\n",
        "    'Recipientage10': 1,\n",
        "    'Recipientageint': 3,\n",
        "    'Relapse': 0,\n",
        "    'aGvHDIIIIV': 0,\n",
        "    'extcGvHD': 0,\n",
        "    'CD34kgx10d6': 5,\n",
        "    'CD3dCD34': 1.5,\n",
        "    'CD3dkgx10d8': 5,\n",
        "    'Rbodymass': 70,\n",
        "    'ANCrecovery': 20,\n",
        "    'PLTrecovery': 50,\n",
        "    'time_to_aGvHD_III_IV': 100,\n",
        "    'survival_time': 200\n",
        "}\n",
        "\n",
        "try:\n",
        "    prediction = predict_survival(input_data)\n",
        "    print(prediction)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7be52e3f-b388-4de5-9f85-5fe8cdf2df3c",
      "metadata": {
        "id": "7be52e3f-b388-4de5-9f85-5fe8cdf2df3c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}